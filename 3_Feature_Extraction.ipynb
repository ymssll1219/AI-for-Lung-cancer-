{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20eda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c897ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_PATH = r\"C:/Users/Administrator/Desktop/lung_multi_omics_aligned_v2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ac1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    'task1': {'mrna': 300, 'mirna': 100}, \n",
    "    'task2': {'mrna': 500, 'mirna': 200}  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a032d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Task: task1 ===\n",
      "  > Processing task1 - mRNA (Top 300 Variance)...\n",
      "    - Training samples used: 704\n",
      "  > Processing task1 - miRNA (Top 100 Variance)...\n",
      "    - Training samples used: 704\n",
      "\n",
      "=== Task: task2 ===\n",
      "  > Processing task2 - mRNA (Top 500 Variance)...\n",
      "    - Training samples used: 671\n",
      "  > Processing task2 - miRNA (Top 200 Variance)...\n",
      "    - Training samples used: 671\n"
     ]
    }
   ],
   "source": [
    "def select_by_variance(task, modality, top_n):\n",
    "    print(f\"  > Processing {task} - {modality} (Top {top_n} Variance)...\")\n",
    "    with h5py.File(H5_PATH, \"r\") as f:\n",
    "        group = \"processed_data\"\n",
    "        mat = f[f\"{group}/expr_matrix_{modality}\"][:]\n",
    "        feat = f[f\"processed_data/{modality}_ids\"][:].astype(str)\n",
    "        split = f[f\"{group}/split\"][:].astype(str)\n",
    "        if f\"{group}/{task}_label\" in f:\n",
    "            lbl = f[f\"{group}/{task}_label\"][:].astype(int)\n",
    "        else:\n",
    "            lbl = f[\"processed_data/task1_label\"][:].astype(int) \n",
    "    if task == 'task1':\n",
    "        valid_mask = (lbl != -1) \n",
    "    else:\n",
    "        valid_mask = (lbl != -1)\n",
    "    train_mask = (split == 'train') & valid_mask\n",
    "    X_train = mat[train_mask]\n",
    "    print(f\"    - Training samples used: {X_train.shape[0]}\")\n",
    "    variances = np.var(X_train, axis=0)\n",
    "    sorted_idx = np.argsort(variances)[::-1][:top_n]\n",
    "    sorted_idx = np.sort(sorted_idx) \n",
    "    selected_feats = feat[sorted_idx]\n",
    "    with h5py.File(H5_PATH, \"a\") as f:\n",
    "        grp = f.require_group(\"feature_selected\")\n",
    "        dn = f\"{task}_selected_{modality}\"\n",
    "        if dn in grp: del grp[dn]\n",
    "        grp.create_dataset(dn, data=np.array([m.encode('utf-8') for m in selected_feats]))\n",
    "        prep_grp = f.require_group(\"preprocessing_params\")\n",
    "        mean_dn = f\"{task}_{modality}_mean\"\n",
    "        std_dn = f\"{task}_{modality}_std\"\n",
    "        if mean_dn in prep_grp: del prep_grp[mean_dn]\n",
    "        if std_dn in prep_grp: del prep_grp[std_dn]\n",
    "        mean_val = X_train.mean(axis=0)\n",
    "        std_val = X_train.std(axis=0)\n",
    "        std_val[std_val == 0] = 1.0 \n",
    "        prep_grp.create_dataset(mean_dn, data=mean_val[sorted_idx])\n",
    "        prep_grp.create_dataset(std_dn, data=std_val[sorted_idx])\n",
    "        grp.attrs['selection_method'] = 'unsupervised_variance'\n",
    "if __name__ == \"__main__\":\n",
    "    for task, cfg in CONFIGS.items():\n",
    "        print(f\"\\n=== Task: {task} ===\")\n",
    "        select_by_variance(task, 'mRNA', cfg['mrna'])\n",
    "        select_by_variance(task, 'miRNA', cfg['mirna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b75944",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"task2\" \n",
    "SKIP_TOP_MRNA = 300\n",
    "TAKE_MRNA = 100\n",
    "SKIP_TOP_MIRNA = 200\n",
    "TAKE_MIRNA = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce88937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_weak_features(modality, skip_n, take_n):\n",
    "    print(f\"\\n>>> Selecting WEAK features for {modality} (Skipping top {skip_n})...\")\n",
    "    with h5py.File(H5_PATH, \"r\") as f:\n",
    "        group = \"processed_data\"\n",
    "        mat = f[f\"{group}/expr_matrix_{modality}\"][:]\n",
    "        feat = f[f\"processed_data/{modality}_ids\"][:].astype(str)\n",
    "        lbl = f[f\"{group}/{task}_label\"][:].astype(int)\n",
    "        split = f[f\"{group}/split\"][:].astype(str)\n",
    "    train_mask = (lbl != -1) & (split == 'train')\n",
    "    X_train = mat[train_mask]\n",
    "    y_train = lbl[train_mask]\n",
    "    mean_train = X_train.mean(axis=0)\n",
    "    std_train = X_train.std(axis=0)\n",
    "    std_train[std_train == 0] = 1\n",
    "    X_train_norm = (X_train - mean_train) / std_train\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=100, \n",
    "        max_depth=4, \n",
    "        eval_metric='logloss', \n",
    "        use_label_encoder=False, \n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_norm, y_train)\n",
    "    importances = model.feature_importances_\n",
    "    sorted_idx = np.argsort(importances)[::-1] \n",
    "\n",
    "    if len(sorted_idx) < skip_n + take_n:\n",
    "        print(f\"Warning: Insufficient number of features, take {take_n} weakest features from the tail\")\n",
    "        weak_idx = sorted_idx[-take_n:]\n",
    "    else:\n",
    "        weak_idx = sorted_idx[skip_n : skip_n + take_n]\n",
    "    weak_idx = np.sort(weak_idx)\n",
    "    selected_feats = feat[weak_idx]\n",
    "    print(f\"Skip Top {skip_n} and select the features that rank {skip_n+1}-{skip_n+take_n}\")\n",
    "    print(f\"- Example: {selected_feats[:5]}\")\n",
    "    with h5py.File(H5_PATH, \"a\") as f:\n",
    "        grp_name = \"feature_selected2\" \n",
    "        grp = f.require_group(grp_name)\n",
    "        dn = f\"{task}_selected_{modality}\"\n",
    "        if dn in grp: del grp[dn]\n",
    "        grp.create_dataset(dn, data=np.array([m.encode('utf-8') for m in selected_feats]))\n",
    "        prep_grp_name = \"preprocessing_params2\"\n",
    "        prep_grp = f.require_group(prep_grp_name)\n",
    "        mean_dn = f\"{task}_{modality}_mean\"\n",
    "        std_dn = f\"{task}_{modality}_std\"\n",
    "        if mean_dn in prep_grp: del prep_grp[mean_dn]\n",
    "        if std_dn in prep_grp: del prep_grp[std_dn]\n",
    "        prep_grp.create_dataset(mean_dn, data=mean_train[weak_idx])\n",
    "        prep_grp.create_dataset(std_dn, data=std_train[weak_idx])\n",
    "        grp.attrs['feature_type'] = 'weak_features'\n",
    "        grp.attrs['selection_method'] = f'skip_top_{skip_n}_take_{take_n}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ebf11fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Selecting WEAK features for mRNA (Skipping top 300)...\n",
      "Skip Top 300 and select the features that rank 301-400\n",
      "- Example: ['ENSG00000131730.16' 'ENSG00000131732.12' 'ENSG00000131791.8'\n",
      " 'ENSG00000131979.20' 'ENSG00000132386.11']\n",
      "\n",
      ">>> Selecting WEAK features for miRNA (Skipping top 200)...\n",
      "Skip Top 200 and select the features that rank 201-250\n",
      "- Example: ['hsa-mir-296' 'hsa-mir-30b' 'hsa-mir-30c-1' 'hsa-mir-30c-2' 'hsa-mir-30d']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    select_weak_features(\"mRNA\", SKIP_TOP_MRNA, TAKE_MRNA)\n",
    "    select_weak_features(\"miRNA\", SKIP_TOP_MIRNA, TAKE_MIRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022b244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
