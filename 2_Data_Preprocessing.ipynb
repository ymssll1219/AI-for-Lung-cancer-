{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e98672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323d991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRNA_ROOT  = r'C:\\Users\\Administrator\\Desktop\\mirna'\n",
    "MRNA_ROOT   = r'C:\\Users\\Administrator\\Desktop\\rna'\n",
    "MAP_PATH    = r'C:\\Users\\Administrator\\Desktop' \n",
    "DST_H5      = r'C:\\Users\\Administrator\\Desktop\\lung_multi_omics_aligned_v2.h5' \n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a040d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_CONFIG = {\n",
    "    'LUAD_T': {'type': 'LUAD_T', 't1': 1, 't2': 0},\n",
    "    'LUAD_N': {'type': 'LUAD_N', 't1': 0, 't2': -1},\n",
    "    'LUSC_T': {'type': 'LUSC_T', 't1': 1, 't2': 1},\n",
    "    'LUSC_N': {'type': 'LUSC_N', 't1': 0, 't2': -1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1614e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "miRNA-LUAD_T: 100%|███████████████████████████████████████████████████████████████| 1038/1038 [00:06<00:00, 161.10it/s]\n",
      "miRNA-LUAD_N: 100%|███████████████████████████████████████████████████████████████████| 92/92 [00:00<00:00, 182.99it/s]\n",
      "miRNA-LUSC_T: 100%|█████████████████████████████████████████████████████████████████| 970/970 [00:05<00:00, 161.86it/s]\n",
      "miRNA-LUSC_N: 100%|███████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 165.26it/s]\n"
     ]
    }
   ],
   "source": [
    "mirna_chunks = []\n",
    "for folder, cfg in FOLDER_CONFIG.items():\n",
    "    fpath = os.path.join(MIRNA_ROOT, folder)\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f'[!] skip {fpath}')\n",
    "        continue\n",
    "    for sample_dir in tqdm(os.listdir(fpath), desc=f'miRNA-{folder}'):\n",
    "        sp = os.path.join(fpath, sample_dir)\n",
    "        if not os.path.isdir(sp): continue\n",
    "        txt = [t for t in os.listdir(sp) if t.endswith('.txt')]\n",
    "        if not txt: continue\n",
    "        \n",
    "        tmp = pd.read_csv(os.path.join(sp, txt[0]), sep='\\t')\n",
    "        tmp = tmp.rename(columns={'miRNA_ID': 'feature_id', 'reads_per_million_miRNA_mapped': 'value'})\n",
    "        tmp['file_id'] = sample_dir\n",
    "        tmp['sample_type'] = cfg['type']\n",
    "        tmp['t1'] = cfg['t1']\n",
    "        tmp['t2'] = cfg['t2']\n",
    "        mirna_chunks.append(tmp)\n",
    "mirna_long = pd.concat(mirna_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa21db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mRNA-LUAD_T: 100%|███████████████████████████████████████████████████████████████████| 534/534 [03:03<00:00,  2.92it/s]\n",
      "mRNA-LUAD_N: 100%|█████████████████████████████████████████████████████████████████████| 58/58 [00:20<00:00,  2.85it/s]\n",
      "mRNA-LUSC_T: 100%|███████████████████████████████████████████████████████████████████| 494/494 [02:52<00:00,  2.87it/s]\n",
      "mRNA-LUSC_N: 100%|█████████████████████████████████████████████████████████████████████| 51/51 [00:18<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "mrna_wide_list = []\n",
    "for folder, cfg in FOLDER_CONFIG.items():\n",
    "    fpath = os.path.join(MRNA_ROOT, folder)\n",
    "    if not os.path.exists(fpath):\n",
    "        print(f'[!] skip {fpath}')\n",
    "        continue\n",
    "    for sample_dir in tqdm(os.listdir(fpath), desc=f'mRNA-{folder}'):\n",
    "        sp = os.path.join(fpath, sample_dir)\n",
    "        if not os.path.isdir(sp): continue\n",
    "        tsv = [t for t in os.listdir(sp) if t.endswith('.tsv')]\n",
    "        if not tsv: continue\n",
    "        file_id = sample_dir\n",
    "        tmp = pd.read_csv(os.path.join(sp, tsv[0]), sep='\\t', skiprows=1, header=0, skipfooter=4, engine='python')\n",
    "        tmp = tmp[['gene_id', 'tpm_unstranded']].rename(columns={'gene_id': 'feature_id', 'tpm_unstranded': 'value'})\n",
    "        tmp = tmp.dropna(subset=['feature_id'])\n",
    "        wide = tmp.set_index('feature_id').T\n",
    "        wide.index = [file_id]          \n",
    "        wide['file_id'] = file_id       \n",
    "        wide['sample_type'] = cfg['type']\n",
    "        wide['t1'] = cfg['t1']\n",
    "        wide['t2'] = cfg['t2']\n",
    "        mrna_wide_list.append(wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d5acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "luad_map = pd.read_csv(os.path.join(MAP_PATH, 'LUAD.tsv'), sep='\\t', usecols=['File ID','Sample ID'])\n",
    "lusc_map = pd.read_csv(os.path.join(MAP_PATH, 'LUSC.tsv'), sep='\\t', usecols=['File ID','Sample ID'])\n",
    "id_map = (pd.concat([luad_map, lusc_map], ignore_index=True)\n",
    "          .rename(columns={'File ID':'file_id', 'Sample ID':'sample_id'})\n",
    "          .set_index('file_id')['sample_id']\n",
    "          .to_dict())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in mirna_chunks:\n",
    "    df['sample_id'] = df['file_id'].map(id_map)\n",
    "mirna_long = pd.concat(mirna_chunks, ignore_index=True)\n",
    "\n",
    "mirna_long = mirna_long.dropna(subset=['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a621847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in mrna_wide_list:\n",
    "    df['sample_id'] = df['file_id'].map(id_map)\n",
    "mrna_dummy = pd.concat(mrna_wide_list, sort=False)\n",
    "mrna_dummy = mrna_dummy.dropna(subset=['sample_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a168d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_mir = mirna_long[['sample_id', 't1', 't2', 'sample_type']].drop_duplicates().set_index('sample_id')\n",
    "mirna_raw = mirna_long.pivot_table(index='sample_id', columns='feature_id', values='value', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5102f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_mrna = mrna_dummy[['sample_id', 't1', 't2', 'sample_type']].set_index('sample_id')\n",
    "mrna_raw = mrna_dummy.set_index('sample_id').select_dtypes('number').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650231be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['t1', 't2']\n",
    "mrna_raw = mrna_raw.drop(columns=[c for c in cols_to_drop if c in mrna_raw.columns])\n",
    "mirna_raw = mirna_raw.groupby(level=0).mean()\n",
    "mrna_raw = mrna_raw.groupby(level=0).mean()\n",
    "meta_mir = meta_mir.groupby(level=0).first() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4744bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples aligned. miRNA: 1040, mRNA: 1117, Common: 1009\n"
     ]
    }
   ],
   "source": [
    "common_samples = sorted(list(set(mirna_raw.index) & set(mrna_raw.index)))\n",
    "print(f'Samples aligned. miRNA: {mirna_raw.shape[0]}, mRNA: {mrna_raw.shape[0]}, Common: {len(common_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2b9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples = np.array(common_samples)\n",
    "mirna_raw = mirna_raw.loc[X_samples]\n",
    "mrna_raw  = mrna_raw.loc[X_samples]\n",
    "t1_l = meta_mir.loc[X_samples, 't1'].astype(int)\n",
    "t2_l = meta_mir.loc[X_samples, 't2'].astype(int)\n",
    "sample_types = meta_mir.loc[X_samples, 'sample_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af312945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Summary (Count by Set):\n",
      "train    704\n",
      "val      153\n",
      "test     152\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patient_ids = np.array([s[:12] for s in X_samples])\n",
    "gss_outer = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=RANDOM_SEED)\n",
    "trainval_idx, test_idx = next(gss_outer.split(X_samples, t1_l, groups=patient_ids))\n",
    "X_trainval = X_samples[trainval_idx]\n",
    "X_test     = X_samples[test_idx]\n",
    "y_trainval = t1_l.iloc[trainval_idx]\n",
    "p_trainval = patient_ids[trainval_idx] \n",
    "gss_inner = GroupShuffleSplit(n_splits=1, test_size=0.1765, random_state=RANDOM_SEED)\n",
    "train_idx_inner, val_idx_inner = next(gss_inner.split(X_trainval, y_trainval, groups=p_trainval))\n",
    "X_train = X_trainval[train_idx_inner]\n",
    "X_val   = X_trainval[val_idx_inner]\n",
    "split_map = pd.Series('train', index=X_samples)\n",
    "split_map.loc[X_val]  = 'val'\n",
    "split_map.loc[X_test] = 'test'\n",
    "\n",
    "print(\"Split Summary (Count by Set):\")\n",
    "print(split_map.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39243182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = set([s[:12] for s in X_train])\n",
    "test_p  = set([s[:12] for s in X_test])\n",
    "overlap = train_p.intersection(test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f70ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_modality(raw_df, train_samples, modality_name):\n",
    "    print(f\"Processing {modality_name}...\")\n",
    "    train_df = raw_df.loc[train_samples]\n",
    "    keep_mask = (train_df < 1).mean(axis=0) < 0.5\n",
    "    filtered_df = raw_df.loc[:, keep_mask]\n",
    "    print(f\"  - Features filtered: {raw_df.shape[1]} -> {filtered_df.shape[1]}\")\n",
    "    log_df = np.log2(filtered_df.clip(lower=0) + 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(log_df.loc[train_samples]) \n",
    "    z_df = pd.DataFrame(scaler.transform(log_df), \n",
    "                        index=log_df.index, \n",
    "                        columns=log_df.columns)\n",
    "    z_df = z_df.replace([np.inf, -np.inf, np.nan], 0)\n",
    "    return z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aa6be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing miRNA...\n",
      "  - Features filtered: 1881 -> 298\n",
      "Processing mRNA...\n",
      "  - Features filtered: 60660 -> 16800\n"
     ]
    }
   ],
   "source": [
    "mirna_z = process_modality(mirna_raw, X_train, \"miRNA\")\n",
    "mrna_z  = process_modality(mrna_raw,  X_train, \"mRNA\")\n",
    "sample_type_map = sample_types.value_counts().to_dict()\n",
    "max_len_sample = max(len(s) for s in X_samples) if len(X_samples) > 0 else 20\n",
    "max_len_mir    = max(len(s) for s in mirna_z.columns) if len(mirna_z.columns) > 0 else 20\n",
    "max_len_mrna   = max(len(s) for s in mrna_z.columns) if len(mrna_z.columns) > 0 else 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4db49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Done. Final file: C:\\Users\\Administrator\\Desktop\\lung_multi_omics_aligned_v2.h5\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(DST_H5, 'w') as h:\n",
    "    g = h.create_group('processed_data')\n",
    "    g.create_dataset('sample_ids',      data=X_samples.astype(f'S{max_len_sample}'), compression='gzip')\n",
    "    g.create_dataset('expr_matrix_miRNA', data=mirna_z.values.astype(np.float32), compression='gzip')\n",
    "    g.create_dataset('expr_matrix_mRNA',  data=mrna_z.values.astype(np.float32),  compression='gzip')\n",
    "    g.create_dataset('task1_label',     data=t1_l.values.astype(np.int8), compression='gzip')\n",
    "    g.create_dataset('task2_label',     data=t2_l.values.astype(np.int8), compression='gzip')\n",
    "    g.create_dataset('split',           data=split_map.values.astype('S5'), compression='gzip')\n",
    "    g.create_dataset('miRNA_ids',       data=np.array(mirna_z.columns).astype(f'S{max_len_mir}'), compression='gzip')\n",
    "    g.create_dataset('mRNA_ids',        data=np.array(mrna_z.columns).astype(f'S{max_len_mrna}'), compression='gzip')\n",
    "    meta = h.create_group('metadata')\n",
    "    meta.attrs['description'] = 'Aligned Multi-omics data (LUAD/LUSC) - Patient Split'\n",
    "    meta.attrs['leakage_check'] = 'Passed: Split by Patient ID; Norm fitted on TRAIN only.'\n",
    "    meta.attrs['filter']      = 'RPM/TPM < 1 in >50% of TRAIN samples deleted'\n",
    "    meta.attrs['norm']        = 'log2(x+1) -> Z-score (fitted on TRAIN)'\n",
    "    meta.attrs['split']       = 'train/val/test = 70/15/15 (approx, group split)'\n",
    "    meta.attrs['sample_counts']= str(sample_type_map)\n",
    "print('>>> Done. Final file:', DST_H5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
